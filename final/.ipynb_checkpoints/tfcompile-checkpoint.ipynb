{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=''\n"
     ]
    }
   ],
   "source": [
    "# This cell can be safely removed and doesn't need to be run.\n",
    "%env CUDA_VISIBLE_DEVICES=''\n",
    "import tensorflow as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mieszkowaw/Code/modele/final/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mieszkowaw/Code/modele/final/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded model from disk\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "conv2d_12 (Conv2D)                  (None, 36, 36, 32)              320         \n",
      "________________________________________________________________________________\n",
      "activation_15 (Activation)          (None, 36, 36, 32)              0           \n",
      "________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNormal (None, 36, 36, 32)              128         \n",
      "________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)                  (None, 36, 36, 32)              9248        \n",
      "________________________________________________________________________________\n",
      "activation_16 (Activation)          (None, 36, 36, 32)              0           \n",
      "________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNormal (None, 36, 36, 32)              128         \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)      (None, 18, 18, 32)              0           \n",
      "________________________________________________________________________________\n",
      "dropout_7 (Dropout)                 (None, 18, 18, 32)              0           \n",
      "________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)                  (None, 18, 18, 64)              18496       \n",
      "________________________________________________________________________________\n",
      "activation_17 (Activation)          (None, 18, 18, 64)              0           \n",
      "________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNormal (None, 18, 18, 64)              256         \n",
      "________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)                  (None, 18, 18, 64)              36928       \n",
      "________________________________________________________________________________\n",
      "activation_18 (Activation)          (None, 18, 18, 64)              0           \n",
      "________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNormal (None, 18, 18, 64)              256         \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)      (None, 9, 9, 64)                0           \n",
      "________________________________________________________________________________\n",
      "dropout_8 (Dropout)                 (None, 9, 9, 64)                0           \n",
      "________________________________________________________________________________\n",
      "flatten_3 (Flatten)                 (None, 5184)                    0           \n",
      "________________________________________________________________________________\n",
      "dense_4 (Dense)                     (None, 512)                     2654720     \n",
      "________________________________________________________________________________\n",
      "activation_19 (Activation)          (None, 512)                     0           \n",
      "________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNormal (None, 512)                     2048        \n",
      "________________________________________________________________________________\n",
      "dropout_9 (Dropout)                 (None, 512)                     0           \n",
      "________________________________________________________________________________\n",
      "dense_5 (Dense)                     (None, 10)                      5130        \n",
      "________________________________________________________________________________\n",
      "activation_20 (Activation)          (None, 10)                      0           \n",
      "================================================================================\n",
      "Total params: 2,727,658\n",
      "Trainable params: 2,726,250\n",
      "Non-trainable params: 1,408\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "\n",
    "tf.keras.backend.set_learning_phase(False)\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.summary(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 0.5: Download tfcompile\n",
    "XLA is still maturing and as of now we have to checkout the development release. System prerequisites are git, the build tool [Bazel](https://docs.bazel.build) and the [Protocol Buffers](https://developers.google.com/protocol-buffers) compiler. I'm also assuming we're running tf-nightly which can be installed via pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%rm -rf /tmp/tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%cd /tmp\n",
    "%cd tensorflow\n",
    "!cp tensorflow/compiler/tf2xla/tf2xla_pb2.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1: Configure the subgraph to compile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### List feeds and fetches\n",
    "tfcompile needs static input shapes so we have to pick a batch size for our image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2xla_pb2\n",
    "\n",
    "config = tf2xla_pb2.Config()\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "for x in model.inputs:\n",
    "    x.set_shape([batch_size] + list(x.shape)[1:])\n",
    "    feed = config.feed.add()\n",
    "    feed.id.node_name = x.op.name\n",
    "    feed.shape.MergeFrom(x.shape.as_proto())\n",
    "\n",
    "for x in model.outputs:\n",
    "    fetch = config.fetch.add()\n",
    "    fetch.id.node_name = x.op.name\n",
    "\n",
    "with open('graph.config.pbtxt', 'w') as f:\n",
    "    f.write(str(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feed {\r\n",
      "  id {\r\n",
      "    node_name: \"input_1\"\r\n",
      "  }\r\n",
      "  shape {\r\n",
      "    dim {\r\n",
      "      size: 1\r\n",
      "    }\r\n",
      "    dim {\r\n",
      "      size: 224\r\n",
      "    }\r\n",
      "    dim {\r\n",
      "      size: 224\r\n",
      "    }\r\n",
      "    dim {\r\n",
      "      size: 3\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "fetch {\r\n",
      "  id {\r\n",
      "    node_name: \"fc1000/Softmax\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "cat graph.config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Freeze graph\n",
    "The graph contains mutable nodes that have to be constants. It's possible to let tfcompile handle this for you (via [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py)) by providing a weights checkpoint along with the graph definition, but as we already have everything loaded we'll make them into constants right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 320 variables.\n",
      "Converted 320 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./graph.pb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.keras.backend.get_session()\n",
    "output_node_names = [node.op.name for node in model.outputs]\n",
    "graphdef = tf.graph_util.convert_variables_to_constants(session, session.graph_def, output_node_names)\n",
    "tf.train.write_graph(graphdef, '.', 'graph.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Use the tf_library build macro to compile the subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting BUILD\n"
     ]
    }
   ],
   "source": [
    "%%writefile BUILD\n",
    "\n",
    "load('@org_tensorflow//tensorflow/compiler/aot:tfcompile.bzl', 'tf_library')\n",
    "\n",
    "tf_library(\n",
    "    name = 'graph',\n",
    "    config = 'graph.config.pbtxt',\n",
    "    cpp_class = 'Graph',\n",
    "    graph = 'graph.pb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......\n",
      "\u001b[32mLoading:\u001b[0m \n",
      "\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
      "\u001b[1A\u001b[K\u001b[35mWARNING: \u001b[0m/home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/core/BUILD:1816:1: in includes attribute of cc_library rule @org_tensorflow//tensorflow/core:framework_headers_lib: '../../../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'external/org_tensorflow/tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/tensorflow.bzl:1143:30\n",
      "\u001b[32mAnalyzing:\u001b[0m target @org_tensorflow//:graph (68 packages loaded)\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mAnalysed target @org_tensorflow//:graph (74 packages loaded).\n",
      "\u001b[32mBuilding:\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mFound 1 target...\n",
      "\u001b[32mBuilding:\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32m[0 / 6]\u001b[0m BazelWorkspaceStatusAction stable-status.txt\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mFrom Executing genrule @org_tensorflow//tensorflow/core:version_info_gen [for host]:\n",
      "\u001b[32m[1,674 / 3,309]\u001b[0m @org_tensorflow//tensorflow/core:version_info_gen; 0s local\n",
      "\u001b[1A\u001b[Kfatal: No names found, cannot describe anything.\n",
      "\u001b[32m[1,674 / 3,309]\u001b[0m @org_tensorflow//tensorflow/core:version_info_gen; 0s local\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mFrom Executing genrule @org_tensorflow//:gen_graph:\n",
      "\u001b[32m[3,332 / 3,336]\u001b[0m Executing genrule @org_tensorflow//:gen_graph; 47s local\n",
      "\u001b[1A\u001b[K2018-01-11 15:27:20.408071: I external/org_tensorflow/tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library\n",
      "2018-01-11 15:27:20.514752: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "\u001b[32m[3,332 / 3,336]\u001b[0m Executing genrule @org_tensorflow//:gen_graph; 47s local\n",
      "\u001b[1A\u001b[KTarget @org_tensorflow//:graph up-to-date:\n",
      "\u001b[32m[3,336 / 3,336]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K  bazel-bin/external/org_tensorflow/libgraph.a\n",
      "\u001b[32m[3,336 / 3,336]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K  bazel-bin/external/org_tensorflow/libgraph.pic.a\n",
      "\u001b[32m[3,336 / 3,336]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K  bazel-bin/external/org_tensorflow/libgraph.so\n",
      "\u001b[32m[3,336 / 3,336]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mElapsed time: 57.837s, Critical Path: 50.33s\n",
      "\u001b[32m[3,336 / 3,336]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32mINFO:\u001b[0m Build completed successfully, 3 total actions\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!bazel build --show_progress_rate_limit=600 @org_tensorflow//:graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Generated by tfcompile, the TensorFlow graph compiler.  DO NOT EDIT!\r\n",
      "//\r\n",
      "// This header was generated via ahead-of-time compilation of a TensorFlow\r\n",
      "// graph.  An object file corresponding to this header was also generated.\r\n",
      "// This header gives access to the functionality in that object file.\r\n",
      "//\r\n",
      "// clang-format off\r\n",
      "\r\n",
      "#ifndef TFCOMPILE_GENERATED_____graph_H_  // NOLINT(build/header_guard)\r\n",
      "#define TFCOMPILE_GENERATED_____graph_H_  // NOLINT(build/header_guard)\r\n",
      "\r\n",
      "\r\n",
      "#include \"tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h\"\r\n",
      "#include \"tensorflow/core/platform/types.h\"\r\n",
      "\r\n",
      "namespace Eigen { struct ThreadPoolDevice; }\r\n",
      "namespace xla { class ExecutableRunOptions; }\r\n",
      "\r\n",
      "// (Implementation detail) Entry point to the function in the object file.\r\n",
      "extern \"C\" void ____graph(\r\n",
      "    void* result, const xla::ExecutableRunOptions* run_options,\r\n",
      "    const void** args, void** temps, tensorflow::int64* profile_counters);\r\n",
      "\r\n",
      "\r\n",
      "// Graph represents a computation previously specified in a\r\n",
      "// TensorFlow graph, now compiled into executable code. This extends the generic\r\n",
      "// XlaCompiledCpuFunction class with statically type-safe arg and result\r\n",
      "// methods. Usage example:\r\n",
      "//\r\n",
      "//   Graph computation;\r\n",
      "//   // ...set args using computation.argN methods\r\n",
      "//   CHECK(computation.Run());\r\n",
      "//   // ...inspect results using computation.resultN methods\r\n",
      "//\r\n",
      "// The Run method invokes the actual computation, with inputs read from arg\r\n",
      "// buffers, and outputs written to result buffers. Each Run call may also use\r\n",
      "// a set of temporary buffers for the computation.\r\n",
      "//\r\n",
      "// By default each instance of this class manages its own arg, result and temp\r\n",
      "// buffers. The AllocMode constructor parameter may be used to modify the\r\n",
      "// buffer allocation strategy.\r\n",
      "//\r\n",
      "// Under the default allocation strategy, this class is thread-compatible:\r\n",
      "// o Calls to non-const methods require exclusive access to the object.\r\n",
      "// o Concurrent calls to const methods are OK, if those calls are made while it\r\n",
      "//   is guaranteed that no thread may call a non-const method.\r\n",
      "//\r\n",
      "// The logical function signature is:\r\n",
      "//   (arg0: f32[1,224,224,3]) -> (f32[1,1000])\r\n",
      "//\r\n",
      "// Memory stats:\r\n",
      "//   arg bytes total:    602112\r\n",
      "//   arg bytes aligned:  602112\r\n",
      "//   temp bytes total:   17815208\r\n",
      "//   temp bytes aligned: 17815232\r\n",
      "class Graph : public tensorflow::XlaCompiledCpuFunction {\r\n",
      " public:\r\n",
      "  // Number of input arguments for the compiled computation.\r\n",
      "  static constexpr size_t kNumArgs = 1;\r\n",
      "\r\n",
      "  // Byte size of each argument buffer. There are kNumArgs entries.\r\n",
      "  static const intptr_t* ArgSizes() {\r\n",
      "    static constexpr intptr_t kArgSizes[kNumArgs] = {602112};\r\n",
      "    return kArgSizes;\r\n",
      "  }\r\n",
      "\r\n",
      "  // Returns static data used to create an XlaCompiledCpuFunction.\r\n",
      "  static const tensorflow::XlaCompiledCpuFunction::StaticData& StaticData() {\r\n",
      "    static XlaCompiledCpuFunction::StaticData* kStaticData = [](){\r\n",
      "      XlaCompiledCpuFunction::StaticData* data =\r\n",
      "        new XlaCompiledCpuFunction::StaticData;\r\n",
      "      data->raw_function = ____graph;\r\n",
      "      data->arg_sizes = ArgSizes();\r\n",
      "      data->num_args = kNumArgs;\r\n",
      "      data->temp_sizes = TempSizes();\r\n",
      "      data->num_temps = kNumTemps;\r\n",
      "      data->result_index = kResultIndex;\r\n",
      "      data->arg_names = StaticArgNames();\r\n",
      "      data->result_names = StaticResultNames();\r\n",
      "      data->program_shape = StaticProgramShape();\r\n",
      "      return data;\r\n",
      "    }();\r\n",
      "    return *kStaticData;\r\n",
      "  }\r\n",
      "\r\n",
      "  Graph(AllocMode alloc_mode = AllocMode::ARGS_RESULTS_PROFILES_AND_TEMPS)\r\n",
      "      : XlaCompiledCpuFunction(StaticData(), alloc_mode) {}\r\n",
      "\r\n",
      "  Graph(const Graph&) = delete;\r\n",
      "  Graph& operator=(const Graph&) = delete;\r\n",
      "\r\n",
      "  // Arg methods for managing input buffers. Buffers are in row-major order.\r\n",
      "  // There is a set of methods for each positional argument, with the following\r\n",
      "  // general form:\r\n",
      "  //\r\n",
      "  // void set_argN_data(void* data)\r\n",
      "  //   Sets the buffer of type T for positional argument N. May be called in\r\n",
      "  //   any AllocMode. Must be called before Run to have an affect. Must be\r\n",
      "  //   called in AllocMode::RESULTS_PROFILES_AND_TEMPS_ONLY for each positional\r\n",
      "  //   argument, to set the argument buffers.\r\n",
      "  //\r\n",
      "  // T* argN_data()\r\n",
      "  //   Returns the buffer of type T for positional argument N.\r\n",
      "  //\r\n",
      "  // T& argN(...dim indices...)\r\n",
      "  //   Returns a reference to the value of type T for positional argument N,\r\n",
      "  //   with dim indices specifying which value. No bounds checking is performed\r\n",
      "  //   on dim indices.\r\n",
      "\r\n",
      "  void set_arg0_data(void* data) {\r\n",
      "    set_arg_data(0, data);\r\n",
      "  }\r\n",
      "  float* arg0_data() {\r\n",
      "    return static_cast<float*>(arg_data(0));\r\n",
      "  }\r\n",
      "  float& arg0(size_t dim0, size_t dim1, size_t dim2, size_t dim3) {\r\n",
      "    return (*static_cast<float(*)[1][224][224][3]>(\r\n",
      "        arg_data(0)))[dim0][dim1][dim2][dim3];\r\n",
      "  }\r\n",
      "  const float* arg0_data() const {\r\n",
      "    return static_cast<const float*>(arg_data(0));\r\n",
      "  }\r\n",
      "  const float& arg0(size_t dim0, size_t dim1, size_t dim2, size_t dim3) const {\r\n",
      "    return (*static_cast<const float(*)[1][224][224][3]>(\r\n",
      "        arg_data(0)))[dim0][dim1][dim2][dim3];\r\n",
      "  }\r\n",
      "\r\n",
      "  // Result methods for managing output buffers. Buffers are in row-major order.\r\n",
      "  // Must only be called after a successful Run call. There is a set of methods\r\n",
      "  // for each positional result, with the following general form:\r\n",
      "  //\r\n",
      "  // T* resultN_data()\r\n",
      "  //   Returns the buffer of type T for positional result N.\r\n",
      "  //\r\n",
      "  // T& resultN(...dim indices...)\r\n",
      "  //   Returns a reference to the value of type T for positional result N,\r\n",
      "  //   with dim indices specifying which value. No bounds checking is performed\r\n",
      "  //   on dim indices.\r\n",
      "  //\r\n",
      "  // Unlike the arg methods, there is no set_resultN_data method. The result\r\n",
      "  // buffers are managed internally, and may change after each call to Run.\r\n",
      "\r\n",
      "  float* result0_data() {\r\n",
      "    return static_cast<float*>(result_data(0));\r\n",
      "  }\r\n",
      "  float& result0(size_t dim0, size_t dim1) {\r\n",
      "    return (*static_cast<float(*)[1][1000]>(\r\n",
      "        result_data(0)))[dim0][dim1];\r\n",
      "  }\r\n",
      "  const float* result0_data() const {\r\n",
      "    return static_cast<const float*>(result_data(0));\r\n",
      "  }\r\n",
      "  const float& result0(size_t dim0, size_t dim1) const {\r\n",
      "    return (*static_cast<const float(*)[1][1000]>(\r\n",
      "        result_data(0)))[dim0][dim1];\r\n",
      "  }\r\n",
      "\r\n",
      " private:\r\n",
      "  // Number of result and temporary buffers for the compiled computation.\r\n",
      "  static constexpr size_t kNumTemps = 10;\r\n",
      "  // The 0-based index of the result tuple in the temporary buffers.\r\n",
      "  static constexpr size_t kResultIndex = 2;\r\n",
      "\r\n",
      "  // Byte size of each result / temporary buffer. There are kNumTemps entries.\r\n",
      "  static const intptr_t* TempSizes() {\r\n",
      "    static constexpr intptr_t kTempSizes[kNumTemps] = {-1, 4000, 8, -1, -1, -1, -1, -1, -1, 17811200};\r\n",
      "    return kTempSizes;\r\n",
      "  }\r\n",
      "\r\n",
      "  // Array of names of each positional argument, terminated by nullptr.\r\n",
      "  static const char** StaticArgNames() {\r\n",
      "    return nullptr;\r\n",
      "  }\r\n",
      "\r\n",
      "  // Array of names of each positional result, terminated by nullptr.\r\n",
      "  static const char** StaticResultNames() {\r\n",
      "    return nullptr;\r\n",
      "  }\r\n",
      "\r\n",
      "  // Shape of the args and results.\r\n",
      "  static const xla::ProgramShape* StaticProgramShape() {\r\n",
      "    return nullptr;\r\n",
      "  }\r\n",
      "};\r\n",
      "\r\n",
      "\r\n",
      "#endif  // TFCOMPILE_GENERATED_____graph_H_\r\n",
      "\r\n",
      "// clang-format on\r\n"
     ]
    }
   ],
   "source": [
    "cat bazel-genfiles/graph.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Write code to invoke the subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing graph.cc\n"
     ]
    }
   ],
   "source": [
    "%%writefile graph.cc\n",
    "\n",
    "#define EIGEN_USE_THREADS\n",
    "#define EIGEN_USE_CUSTOM_THREAD_POOL\n",
    "\n",
    "#include \"graph.h\"\n",
    "#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n",
    "\n",
    "extern \"C\" int run(float *input, float *output, int input_size, int output_size) {\n",
    "  Eigen::ThreadPool tp(std::thread::hardware_concurrency());\n",
    "  Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());\n",
    "  Graph graph;\n",
    "  graph.set_thread_pool(&device);\n",
    "\n",
    "  std::copy(input, input + input_size, graph.arg0_data());\n",
    "  auto ok = graph.Run();\n",
    "  if (not ok) return -1;\n",
    "  std::copy(graph.result0_data(), graph.result0_data() + output_size, output);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 4: Create the final binary.\n",
    "Instead of calling `gcc` directly, and as Bazel is already required for building the tfcompile tool, we'll make a `cc_binary` rule. In fact, we could just have done one big BUILD file directly after having cloned the TensorFlow repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to BUILD\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a BUILD\n",
    "\n",
    "cc_binary(\n",
    "    name = \"libmodel.so\",\n",
    "    srcs = [\"graph.cc\"],\n",
    "    deps = [\":graph\", \"//third_party/eigen3\"],\n",
    "    linkopts = [\"-lpthread\"],\n",
    "    linkshared = 1,\n",
    "    copts = [\"-fPIC\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLoading:\u001b[0m \n",
      "\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
      "\u001b[1A\u001b[K\u001b[35mWARNING: \u001b[0m/home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/core/BUILD:1816:1: in includes attribute of cc_library rule @org_tensorflow//tensorflow/core:framework_headers_lib: '../../../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'external/org_tensorflow/tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/carl/.cache/bazel/_bazel_carl/e5cce820cc082410b4fcc604db349066/external/org_tensorflow/tensorflow/tensorflow.bzl:1143:30\n",
      "\u001b[32mAnalyzing:\u001b[0m target @org_tensorflow//:libmodel.so (2 packages loaded)\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mAnalysed target @org_tensorflow//:libmodel.so (2 packages loaded).\n",
      "\u001b[32mBuilding:\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mFound 1 target...\n",
      "\u001b[32mBuilding:\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32m[0 / 5]\u001b[0m BazelWorkspaceStatusAction stable-status.txt\n",
      "\u001b[1A\u001b[KTarget @org_tensorflow//:libmodel.so up-to-date:\n",
      "\u001b[32m[632 / 632]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K  bazel-bin/external/org_tensorflow/libmodel.so\n",
      "\u001b[32m[632 / 632]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mElapsed time: 1.852s, Critical Path: 0.56s\n",
      "\u001b[32m[632 / 632]\u001b[0m no action running\n",
      "\u001b[1A\u001b[K\u001b[32mINFO:\u001b[0m Build completed successfully, 1 total action\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!bazel build --show_progress_rate_limit=60 @org_tensorflow//:libmodel.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "libmodel = np.ctypeslib.load_library('libmodel', 'bazel-bin/external/org_tensorflow')\n",
    "libmodel.run.argtypes = [\n",
    "    np.ctypeslib.ndpointer(np.float32, ndim=4, shape=(1, 224, 224, 3), flags=('c', 'a')),\n",
    "    np.ctypeslib.ndpointer(np.float32, ndim=2, shape=(1, 1000), flags=('c', 'a', 'w')),\n",
    "    np.ctypeslib.ctypes.c_int,\n",
    "    np.ctypeslib.ctypes.c_int]\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    x = np.require(x, np.float32, ('c', 'a'))\n",
    "    y = np.require(np.zeros((1, 1000)), np.float32, ('c', 'a', 'w'))\n",
    "    libmodel.run(x, y, x.size, y.size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n02110806', 'basenji', 0.60816735),\n",
       " ('n02441942', 'weasel', 0.10849755),\n",
       " ('n02091244', 'Ibizan_hound', 0.081580825),\n",
       " ('n02124075', 'Egyptian_cat', 0.044705715),\n",
       " ('n02123597', 'Siamese_cat', 0.025189402)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "image_path = input()\n",
    "\n",
    "x = image.img_to_array(image.load_img(image_path, target_size=(224, 224)))\n",
    "x = x[None, ...]\n",
    "x = preprocess_input(x)\n",
    "y = predict(x)\n",
    "decode_predictions(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 ms ± 199 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "191 ms ± 604 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model.predict(x)\n",
    "%timeit predict(x)\n",
    "np.testing.assert_allclose(model.predict(x), predict(x), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.96 s ± 456 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model = tf.keras.applications.ResNet50()\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "- https://www.tensorflow.org/performance/xla/tfcompile\n",
    "- https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html\n",
    "- https://youtu.be/kAOanJczHA0\n",
    "- https://youtu.be/2IOPpyyuLkc"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "## Step 0: Model\n",
     "Before we start compiling a graph we need to build our graph. Let's keep it simple by just loading a pretrained image classifier."
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
